{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e818d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# 1.1 Notebook - VDJ RBD Data exploration, preprocessing & embedding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Author: Lena Erlach"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Created: 2024-01-16"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Last modified: 2024-07-17"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime, date\n",
    "\n",
    "todays_date = str(datetime.now().date())\n",
    "\n",
    "display(Markdown(f'# 1.1 Notebook - VDJ RBD Data exploration, preprocessing & embedding'))\n",
    "display(Markdown(f'Author: Lena Erlach'))\n",
    "display(Markdown(f'Created: 2024-01-16'))\n",
    "display(Markdown(f'Last modified: {todays_date}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34ffcc7-aa8e-4c0b-9afc-20ed1e7ffe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions used \n",
    "\n",
    "def filter_intersection(datasets: list, seq_col: str, seq_complete_col: str = \"seq_complete_HC\", verbose: bool = False):\n",
    "    '''\n",
    "    Args: \n",
    "        datasets: list of len 2\n",
    "            list of the 2 pandas dfs that should be filtered\n",
    "        seq_col: str\n",
    "            column name of sequences, which should be the basis of filtering\n",
    "        seq_complete_col: str\n",
    "            column name of with bool values, if sequence is complete\n",
    "        verbose: bool, default = False\n",
    "    Returns: \n",
    "        datasets_filt1, datasets_filt2: 2 pandas dataframes\n",
    "            Returns the 2 filtered pandas dfs\n",
    "    '''\n",
    "    \n",
    "    # filter sequences that are not complete\n",
    "    datasets[0] = datasets[0][datasets[0][seq_complete_col] == True]\n",
    "    datasets[1] = datasets[1][datasets[1][seq_complete_col] == True]\n",
    "    \n",
    "    # get intersection per sample\n",
    "    intersect_m1 = np.intersect1d(datasets[0][seq_col], datasets[1][seq_col])\n",
    "    \n",
    "    # print out number of sequences intersecting\n",
    "    if verbose is True: print(\"number of intersecting sequences:\", len(intersect_m1))\n",
    "    \n",
    "    # filter overlapping sequences per mouse (s1&s2) and (s3&s4)! \n",
    "    datasets_filt = []\n",
    "    \n",
    "    for i in range(len(datasets)):\n",
    "        d_filt = datasets[i][~np.isin(datasets[i][seq_col], intersect_m1)]\n",
    "        datasets_filt.append(d_filt)    \n",
    "    \n",
    "    return(datasets_filt[0], datasets_filt[1])\n",
    "    \n",
    "    \n",
    "def preprocess_raw(df, seq_col_HC, seq_col_LC, HC_prefix='VDJ_aa', LC_prefix='VJ_aa', \n",
    "                   HC_colsuffix = 'HC', LC_colsuffix='LC'):\n",
    "    '''\n",
    "    Args: \n",
    "        df: pandas dataframe\n",
    "            Raw pandas dataframe with the sequences in column 'seq_col'\n",
    "        seq_col: str\n",
    "            column name of sequences, which should be the basis of filtering\n",
    "        HC_prefix, LC_prefix: str\n",
    "            Prefix of the column names that are included when checking for nan values; e.g. 'VDJ_aa' for HCs, or 'VJ_aa'for LCs\n",
    "        HC_colsuffix, LC_colsuffix: str\n",
    "            suffix for the column added to the dataframe, True when nan values existent in checked columsn;\n",
    "\n",
    "    Returns: \n",
    "        df: pandas dataframes\n",
    "            Returns the filtered pandas dataframes\n",
    "    '''\n",
    "\n",
    "    # add a column based on HC complete or LC complete\n",
    "    col_H = [s for s in df.columns.tolist() if HC_prefix in s]\n",
    "    col_L = [s for s in df.columns.tolist() if LC_prefix in s]\n",
    "    df[\"seq_complete_\"+HC_colsuffix] = df[col_H].notna().all(axis=1)\n",
    "    df[\"seq_complete_\"+LC_colsuffix] = df[col_L].notna().all(axis=1)\n",
    "    \n",
    "    \n",
    "    # filter stop codons '*' from sequences \n",
    "    df = df[~df[seq_col].str.contains(r'\\*', na=False)]\n",
    "\n",
    "\n",
    "    # strip last under score from VDJ & VJ sequence\n",
    "    df[seq_col_HC] = df[seq_col_HC].str.strip('_')\n",
    "    df[seq_col_LC] = df[seq_col_LC].str.strip('_')\n",
    "\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "# save fasta files of sequences\n",
    "# Function adapted from the LModeling_OVA repo \n",
    "def save_fasta_file(sequence_df, col_name = \"VDJ_aaSeq\", id_name = \"barcode\", n_seq = 500, \n",
    "                    subdirectory = \"data/\", file_prefix = \"Seq\"):\n",
    "    \"\"\"\n",
    "    Function that writes fasta files from a protein sequences pd.DataFrame; number of sequences per file can be set (in case for the Language\n",
    "    model embeddings) that will be set to how many sequences can be embedded in one job; \n",
    "    \n",
    "    Note: \n",
    "    Sequences won't be filtered, processed or trimmed;\n",
    "        Args:\n",
    "            sequence_df (pd.DataFrame): dataframe that contains the sequences in the col_name column and sequence fasta ids in id_name column;\n",
    "\n",
    "            col_name (string): the name of the dataframe column that stores the protein sequences;\n",
    "\n",
    "            id_name (string): the name of the dataframe column that stores the sequence ids that are to be used as identifier in the fasta file;\n",
    "\n",
    "            n_seq (int): number of sequeces to be written per fasta file; (depends on how many can be embedded in one ESM embedding job)\n",
    "\n",
    "            subdirectory (string): path leading to the folder where fasta files should be stored;\n",
    "\n",
    "            file_prefix (string): file prefix for the fasta file names;\n",
    "\n",
    "        \"\"\"\n",
    "    import math\n",
    "    n_start = 0\n",
    "    num_rounds = math.ceil(len(sequence_df.loc[sequence_df.seq_complete == True, col_name]) / n_seq)\n",
    "\n",
    "    for r in range(num_rounds):\n",
    "        print(f'Save fasta: {r}')\n",
    "        if r < num_rounds - 1:\n",
    "            # Downlsample OVA sequences\n",
    "            OVA_VDJs = sequence_df[id_name].tolist()[n_start:n_start + n_seq]\n",
    "            barcodes = sequence_df[id_name].tolist()[n_start:n_start + n_seq]\n",
    "            n_start += n_seq\n",
    "            # save fasta files\n",
    "            ofile = open(os.path.join(subdirectory, file_prefix + \"fasta_\" + str(r) + \".txt\"), \"w\")\n",
    "            for i, bc in enumerate(barcodes):\n",
    "                ofile.write(\">\" + bc + \"\\n\" + OVA_VDJs[i] + \"\\n\")\n",
    "            ofile.close()\n",
    "            print(\"file saved:\" + str(r))\n",
    "\n",
    "        elif r == num_rounds - 1:\n",
    "            OVA_VDJs = sequence_df[col_name].tolist()[n_start:]\n",
    "            barcodes = sequence_df[id_name].tolist()[n_start:]\n",
    "            # print(\"last round\")\n",
    "            # save fasta files\n",
    "            ofile = open(os.path.join(subdirectory, file_prefix + \"fasta_\" + str(r) + \".txt\"), \"w\")\n",
    "            for i, bc in enumerate(barcodes):\n",
    "                # print(\">\" + bc)\n",
    "                ofile.write(\">\" + bc + \"\\n\" + OVA_VDJs[i] + \"\\n\")\n",
    "            ofile.close()\n",
    "            print(\"last file saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab67ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the specifics for the filtering\n",
    "dataset = \"RBD\"\n",
    "seq_col = \"VDJ_aaSeq\"\n",
    "seq_col_LC = \"VJ_aaSeq\" # column name of the sequence to filter for (VDJ_VJ_aaSeq, VDJ_aaSeq, \n",
    "seq_complete_col = \"seq_complete_HC\" # column name of sequence is complete or not (seq_complete, seq_complete_HC, seq_complete_ls) \n",
    "sample_names = [\"s1\", \"s2\"]    # entries in the sample column \n",
    "verbose = True\n",
    "ROOT_DIR = '../..'\n",
    "\n",
    "inputFile_raw = os.path.join(ROOT_DIR, 'data/raw/VDJ_mixcr_modelling_RBD_Wuhan_raw.csv')\n",
    "\n",
    "# just save file again, if updated! Most up to date file is done on 28.09.2023 --> LC underscore trimmed now, as well!\n",
    "outputPath_processed = os.path.join(ROOT_DIR, f'data/processed/processed_{dataset}_{seq_col}_df_{str(date.today())}.csv')\n",
    "\n",
    "# fasta file path \n",
    "outputPath_processed_fasta = os.path.join(ROOT_DIR, 'data/processed/fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e28dad0-cc91-401c-846b-f785ef5cfa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of specific: 1122 and nonspecific sequences: 5724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49840/476931900.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[seq_col_HC] = df[seq_col_HC].str.strip('_')\n",
      "/tmp/ipykernel_49840/476931900.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[seq_col_LC] = df[seq_col_LC].str.strip('_')\n",
      "/tmp/ipykernel_49840/1202386681.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  RBD_seq_raw['group_id'][RBD_seq_raw['group_id'] == g_id] = rep\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "RBD_seq_raw1 = pd.read_csv(inputFile_raw, index_col=0)\n",
    "RBD_seq_raw1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "RBD_seq_raw1[seq_col] = RBD_seq_raw1[seq_col].astype(str)\n",
    "print(f'Number of specific: {len(RBD_seq_raw1[RBD_seq_raw1.group_id == \"LN_Wuhan_pos\"])} and nonspecific sequences: {len(RBD_seq_raw1[RBD_seq_raw1.group_id == \"LN_Wuhan_neg\"])}')\n",
    "\n",
    "RBD_seq_raw = preprocess_raw(RBD_seq_raw1, seq_col, seq_col_LC, HC_prefix='VDJ_aa', LC_prefix='VJ_aa', \n",
    "                             HC_colsuffix = 'HC', LC_colsuffix='LC')\n",
    "\n",
    "# replace group labels \n",
    "for rep, g_id in zip([1, 2], ['LN_Wuhan_pos', 'LN_Wuhan_neg']):\n",
    "    RBD_seq_raw['group_id'][RBD_seq_raw['group_id'] == g_id] = rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a037a2-164f-4461-8a20-6ae0d0f9edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique, complete, non-overlapping VDJ_aaSeq sequences in the RBD\n",
      "Total: 3784\n",
      "s1: 663\n",
      "s2: 3121\n",
      "\n",
      "Number of unique, non-overlapping VH_VL sequences\n",
      "Total: 3593\n",
      "s1: 642\n",
      "s2: 2951\n"
     ]
    }
   ],
   "source": [
    "# split unfiltered dataset by samples and drop duplicated sequencs per sample\n",
    "s1_VDJ_VJs_uf = RBD_seq_raw[RBD_seq_raw.sample_id == sample_names[0]].drop_duplicates(subset=seq_col)\n",
    "s2_VDJ_VJs_uf = RBD_seq_raw[RBD_seq_raw.sample_id == sample_names[1]].drop_duplicates(subset=seq_col)\n",
    "\n",
    "\n",
    "\n",
    "# Filter sequences that are in the intersection within the mice      \n",
    "s1_VDJ_VJs, s2_VDJ_VJs = filter_intersection([s1_VDJ_VJs_uf, s2_VDJ_VJs_uf], seq_col, seq_complete_col, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "# combine to one dataframe!\n",
    "seq_df = pd.concat([s1_VDJ_VJs, s2_VDJ_VJs])\n",
    "\n",
    "\n",
    "# drop duplicates in case sequences overlap in across mice (but then dropping them\n",
    "# is fine because they show up in the same sample, specific or not specific)\n",
    "seq_df = seq_df.drop_duplicates(subset=[seq_col]).reset_index(drop=True)\n",
    "\n",
    "# add column Seq_id column \n",
    "seq_df['seq_id'] = [str(x)+'_'+str(seq_df['sample_id'][x]) for x in seq_df.index]\n",
    "\n",
    "if verbose is True:\n",
    "    print(f'\\nNumber of unique, complete, non-overlapping {seq_col} sequences in the {dataset}')\n",
    "    print(\"Total:\", len(seq_df))\n",
    "    print(\"s1:\", len(seq_df[seq_df[\"sample_id\"] == \"s1\"]))\n",
    "    print(\"s2:\", len(seq_df[seq_df[\"sample_id\"] == \"s2\"]))\n",
    "\n",
    "seq_df_comp = seq_df[seq_df.seq_complete == True]\n",
    "if verbose is True:\n",
    "    print(\"\\nNumber of unique, non-overlapping \" + \"VH_VL\" + \" sequences\")\n",
    "    print(\"Total:\", len(seq_df_comp))\n",
    "    print(\"s1:\", len(seq_df_comp[seq_df_comp[\"sample_id\"] == \"s1\"]))\n",
    "    print(\"s2:\", len(seq_df_comp[seq_df_comp[\"sample_id\"] == \"s2\"]))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfa0cc",
   "metadata": {},
   "source": [
    "### Save dataframe and fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e54ed830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save fasta: 0\n",
      "last file saved\n"
     ]
    }
   ],
   "source": [
    "# Save sequences as fasta file\n",
    "if not os.path.exists(outputPath_processed_fasta):\n",
    "    os.makedirs(outputPath_processed_fasta)\n",
    "    \n",
    "save_fasta_file(seq_df, col_name = \"VDJ_aaSeq\", id_name = 'seq_id', n_seq = len(seq_df['seq_id']), \n",
    "                subdirectory = outputPath_processed_fasta, file_prefix = f'{dataset}_VDJ_aaSeq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24743913-5fd6-460c-a3e7-6d47dfc4ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed dataframe\n",
    "seq_df.to_csv(outputPath_processed, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
